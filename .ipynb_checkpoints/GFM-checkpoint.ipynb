{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "sns.set(style='white')\n",
    "style.use(\"fivethirtyeight\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset,DataLoader \n",
    "from torch.optim import Adam,SGD,RMSprop\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_, kaiming_normal_\n",
    "from torch.nn.parameter import Parameter\n",
    "import time\n",
    "import gc\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from utils import * \n",
    "import pickle as pkl\n",
    "datasets = ['mr','ohsumed','R8','R52','weibo_yiqing']\n",
    "d = 'R8'\n",
    "if d not in datasets:\n",
    "    print(\"error dataset\")\n",
    "else:\n",
    "    A, X, Y, _, _, _, _, _, _ = load_data(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('loading total set')\n",
    "A, M = preprocess_adj(A)\n",
    "X = preprocess_features(X)\n",
    "# print('loading validation set')\n",
    "# val_adj, val_mask = preprocess_adj(val_adj)\n",
    "# val_feature = preprocess_features(val_feature)\n",
    "# print('loading test set')\n",
    "# test_adj, test_mask = preprocess_adj(test_adj)\n",
    "# test_feature = preprocess_features(test_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = X.shape[0]\n",
    "total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.where(Y)[1]\n",
    "sns.countplot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape,X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adj = torch.Tensor(A[:int(0.8 * total_samples)])\n",
    "train_feature = torch.Tensor(X[:int(0.8 * total_samples)])\n",
    "train_y = torch.LongTensor(Y[:int(0.8 * total_samples)])\n",
    "\n",
    "val_adj = torch.Tensor(A[int(0.8 * total_samples):int(0.9 * total_samples)])\n",
    "val_feature = torch.Tensor(X[int(0.8 * total_samples):int(0.9 * total_samples)])\n",
    "val_y = torch.LongTensor(Y[int(0.8 * total_samples):int(0.9 * total_samples)])\n",
    "\n",
    "test_adj = torch.Tensor(A[int(0.9 * total_samples):])\n",
    "test_feature = torch.Tensor(X[int(0.9 * total_samples):])\n",
    "test_y = torch.LongTensor(Y[int(0.9 * total_samples):])\n",
    "\n",
    "train_mask = torch.Tensor(M[:int(0.8 * total_samples)])\n",
    "val_mask =torch.Tensor(M[int(0.8 * total_samples):int(0.9 * total_samples)])\n",
    "test_mask =torch.Tensor(M[int(0.9 * total_samples):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adj.shape,train_feature.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_adj.shape,val_feature.shape,val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adj.shape,test_feature.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(test_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split mini-batch\n",
    "def getBatch(i, bs, A, X, Y,mask):\n",
    "    return A[i*bs:(i+1)*bs],X[i*bs:(i+1)*bs],Y[i*bs:(i+1)*bs],mask[i*bs:(i+1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "weight_decay = 0.\n",
    "\n",
    "num_class = 8\n",
    "train_samples = train_y.shape[0]\n",
    "test_samples = test_y.shape[0]\n",
    "val_samples = val_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GFM-GC model \n",
    "from layers import GraphConvolution\n",
    "from torch.nn.init import xavier_uniform_, kaiming_normal_\n",
    "class GFMGC(nn.Module):\n",
    "    def __init__(self, num_class, input_dim, fb_size):\n",
    "        super(GFMGC,self).__init__()\n",
    "        \n",
    "        self.num_class = num_class\n",
    "        self.input_dim = input_dim\n",
    "#         self.W = nn.Parameter(torch.FloatTensor(input_dim, fb_size))\n",
    "        \n",
    "        self.gru = nn.GRU(self.input_dim,\n",
    "                          128,\n",
    "                          bidirectional = True,\n",
    "                          batch_first = True,\n",
    "                          bias = True)\n",
    "    \n",
    "        self.fc1 = nn.Sequential(nn.Linear(300 + 128 * 2,128),\n",
    "                                 nn.ReLU(inplace = True),\n",
    "                                 nn.BatchNorm1d(128),\n",
    "                                 nn.Linear(128,64),\n",
    "                                 nn.ReLU(inplace = True),\n",
    "                                 nn.BatchNorm1d(64),\n",
    "                                 nn.Linear(64,num_class),\n",
    "                                 \n",
    "                                 \n",
    "            )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def cal_gfm(self,x,adj,bs,seq):# x-[bs,seq,emb_size]  adj:[bs,seq,seq]\n",
    "\n",
    "        left = x.repeat(1,1,seq).view(bs,seq * seq ,-1)\n",
    "        right = x.repeat(1,seq,1)\n",
    "        fi = left * right   \n",
    "        adj = adj.view(bs,-1).unsqueeze(2)\n",
    "        return torch.sum(fi,dim = 1)\n",
    "                                                                              \n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                kaiming_normal_(p)\n",
    "        \n",
    "    def forward(self,x,adj,mask):# x:[bs,seq,emb_size]  adj:[bs,seq,seq]\n",
    "        x = x * mask\n",
    "        bs, seq, emb = x.shape\n",
    "        h = self.gru(x)[0][:,-1,:]\n",
    "#         print(h.shape)\n",
    "        gfm = self.cal_gfm(x,adj,bs,seq)\n",
    "#         gfm = F.dropout(gfm,0.1,training = self.training)\n",
    "        logit = self.fc1(torch.cat([h,gfm],dim=1))\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GFMGC(num_class = 8, input_dim = 300,fb_size=100).cuda()\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr = lr,weight_decay = weight_decay)\n",
    "lossfunc = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train() \n",
    "        print('epoch {}'.format(epoch + 1))\n",
    "        train_loss = []\n",
    "        train_acc = 0.\n",
    "        for i in tqdm(range(train_samples // batch_size + 1)):\n",
    "            adj_batch,feature_batch, y_batch, mask_batch = getBatch(i, batch_size, train_adj, train_feature, train_y,train_mask)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(feature_batch.cuda(),adj_batch.cuda(),mask_batch.cuda())\n",
    "            loss = lossfunc(logits, y_batch.cuda())\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            pred = torch.max(logits,1)[1]\n",
    "            \n",
    "            train_correct = (pred.cpu()  == y_batch).sum()\n",
    "            \n",
    "            train_acc += train_correct\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('train_loss = {:0.4f}, train_acc = {:0.4f}'.format(np.mean(train_loss), train_acc / train_samples))\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = []\n",
    "        val_acc = 0.\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(test_samples // batch_size + 1)):\n",
    "                adj_batch,feature_batch, y_batch, mask_batch = getBatch(i, batch_size, test_adj, test_feature, test_y,test_mask)\n",
    "                logits = model(feature_batch.cuda(),adj_batch.cuda(),mask_batch.cuda())\n",
    "                loss = lossfunc(logits, y_batch.cuda())\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                pred = torch.max(logits,1)[1]\n",
    "                print(pred)\n",
    "                val_correct = (pred.cpu() == y_batch).sum()\n",
    "\n",
    "                val_acc += val_correct\n",
    "            # best_acc\n",
    "            if best_acc < val_acc / test_samples:\n",
    "                best_acc = val_acc / test_samples\n",
    "            print('test_loss = {:0.4f},  test_acc = {:0.4f}, best_acc = {:0.4f}'.format(np.mean(val_loss), val_acc / test_samples,\\\n",
    "                                                                                     best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
